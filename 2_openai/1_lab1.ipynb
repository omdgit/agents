{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 1\n",
    "\n",
    "And now! Our first look at OpenAI Agents SDK\n",
    "\n",
    "You won't believe how lightweight this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">The OpenAI Agents SDK Docs</h2>\n",
    "            <span style=\"color:#00bfff;\">The documentation on OpenAI Agents SDK is really clear and simple: <a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a> and it's well worth a look.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an agent with name, instructions, model\n",
    "\n",
    "agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the autonomous AI agent bring a ladder to work?\n",
      "\n",
      "Because it wanted to reach new heights in its programming!\n"
     ]
    }
   ],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "with trace(\"Telling a joke\"):\n",
    "    result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Vibe Coding\n",
    "\n",
    "This concludes the initial session on the OpenAI agents SDK. This sidebar discusses \"vibe coding,\" a term coined by Andrej Karpathy in a viral social media post.\n",
    "\n",
    "*   **Definition:** Vibe coding is a productive and enjoyable method of programming with LLMs. It involves generating some code, tweaking it, generating more, and rapidly making progress, especially when navigating new frameworks. It's an ad-hoc, fluid way of working.\n",
    "*   **Endorsement and Warning:** The speaker strongly encourages vibe coding but warns that it's easy to be led astray by LLMs, get into trouble, and become stuck. The following five tips are offered as a \"survival guide\" to do it well.\n",
    "\n",
    "---\n",
    "\n",
    "### Five Tips for Effective Vibe Coding\n",
    "\n",
    "#### 1. Good Vibes (Effective Prompting)\n",
    "Focus on creating a high-quality, reusable prompt for the LLM.\n",
    "*   **Ask for Short, Concise Code:** LLMs tend to be verbose, packaging code with many exception handlers in a long-winded way. Explicitly ask for concise and clean code.\n",
    "*   **Request Current APIs:** Mention today's date in the prompt and ask the LLM to use APIs that are current as of that date. This prevents it from using older APIs that are prevalent in its training data.\n",
    "\n",
    "#### 2. Vibe, but Verify (Cross-Validation)\n",
    "Don't rely on a single LLM's answer.\n",
    "*   **Use Multiple LLMs:** Ask the same question to two or three different LLMs (e.g., ChatGPT and Claude).\n",
    "*   **Rationale:** You can learn from both answers. Often, one LLM's response will be too verbose or miss the point, while another will be spot-on. This technique helps verify the quality of the solution.\n",
    "\n",
    "#### 3. Step up the Vibe (Incremental Generation)\n",
    "Avoid generating large, monolithic blocks of code at once.\n",
    "*   **The Problem to Avoid:** Generating 200 lines of code and then trying to debug it when it doesn't work is an ineffective approach. This code is often unwieldy and contains multiple bugs.\n",
    "*   **The Solution:** Generate code in small, independently testable pieces, such as function-by-function or about ten lines at a time.\n",
    "*   **The Trick:** If you don't know how to break a large problem into smaller steps, ask the LLM to do it for you.\n",
    "    *   **Prompt for a Plan, Not Code:** Ask the LLM, \"Tell me the 4 or 5 simple, bite-sized steps to solve my problem, where each step can be tested independently.\"\n",
    "    *   **Execute Step-by-Step:** Once you have the plan, ask the LLM to generate the code and a corresponding test for each small step, one at a time. This allows you to build a large, perfect solution from small, verified parts.\n",
    "\n",
    "#### 4. Vibe and Validate (Peer Review with LLMs)\n",
    "Use one LLM to critique the output of another. This mirrors the \"evaluator-optimizer\" design pattern.\n",
    "*   **The Workflow:**\n",
    "    1.  Ask an LLM for a solution to your problem.\n",
    "    2.  Take both the original question and the generated answer to a *different* LLM.\n",
    "    3.  Ask the second LLM to validate the first answer: \"Please confirm this is an appropriate answer. Can you make it more concise, better structured, or are there any bugs?\"\n",
    "*   **Benefit:** The second LLM will often detect problems or suggest cleaner, simpler improvements.\n",
    "\n",
    "#### 5. Vibe with Variety (Exploring Multiple Solutions)\n",
    "Force the LLM to consider different approaches to a problem.\n",
    "*   **Ask for Multiple Versions:** Instead of asking for one solution, ask for three different solutions or ways to approach the same problem, especially for small (e.g., 10-line) code snippets.\n",
    "*   **Benefit:** This forces the model to contemplate various methods, which can result in you getting a better overall solution.\n",
    "*   **Ask for Explanations:** As part of this, ask the LLM to explain the rationale behind each different approach. This forces the model to think through its process and has the added benefit of explaining the code to you so you can better understand it.\n",
    "\n",
    "---\n",
    "\n",
    "### The Final, Overarching Point: Understand the Code\n",
    "\n",
    "*   Although not one of the numbered tips, it is crucial to always understand the code you are working with.\n",
    "*   If any part of the LLM-generated code is not immediately clear, go back and ask the LLM to explain it clearly until you understand every single line.\n",
    "*   **Rationale:** Vibe coding is fun and powerful, but it becomes painful and frustrating when something breaks and you don't understand what's happening. It's important to \"stay in touch with what's going on.\"\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The speaker concludes that vibe coding is great fun, super productive, and should definitely be utilized, and hopes this guide will be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
