{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Research\n",
    "\n",
    "One of the classic cross-business Agentic use cases! This is huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">A Deep Research agent is broadly applicable to any business area, and to your own day-to-day activities. You can make use of this yourself!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, gen_trace_id, function_tool\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "# import sendgrid\n",
    "import os\n",
    "# from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from typing import Dict\n",
    "from IPython.display import display, Markdown\n",
    "import brevo_python \n",
    "import brevo_python \n",
    "from brevo_python.api import transactional_emails_api \n",
    "from brevo_python.models.send_smtp_email import SendSmtpEmail \n",
    "from brevo_python.models.send_smtp_email_to import SendSmtpEmailTo \n",
    "from brevo_python.models.send_smtp_email_sender import SendSmtpEmailSender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Hosted Tools\n",
    "\n",
    "OpenAI Agents SDK includes the following hosted tools:\n",
    "\n",
    "The `WebSearchTool` lets an agent search the web.  \n",
    "The `FileSearchTool` allows retrieving information from your OpenAI Vector Stores.  \n",
    "The `ComputerTool` allows automating computer use tasks like taking screenshots and clicking.\n",
    "\n",
    "### Important note - API charge of WebSearchTool\n",
    "\n",
    "This is costing me 2.5 cents per call for OpenAI WebSearchTool. That can add up to $2-$3 for the next 2 labs. We'll use low cost Search tools with other platforms, so feel free to skip running this if the cost is a concern.\n",
    "\n",
    "Costs are here: https://platform.openai.com/docs/pricing#web-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given a search term, you search the web for that term and \\\n",
    "produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300 \\\n",
    "words. Capture the main points. Write succintly, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\"\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[WebSearchTool(search_context_size=\"low\")],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of mid-2025, several AI agent frameworks have emerged, each offering unique capabilities for developing intelligent, autonomous systems.\n",
       "\n",
       "**LangChain** is a Python-based framework that enables developers to build applications powered by large language models (LLMs). It offers modular components for creating and managing workflows, integrated memory for stateful applications, and compatibility with multiple LLMs and APIs. LangChain is ideal for conversational AI, automated research assistants, and document analysis. ([linkedin.com](https://www.linkedin.com/pulse/top-5-frameworks-building-ai-agents-2025-sahil-malhotra-wmisc?utm_source=openai))\n",
       "\n",
       "**LangGraph** extends LangChain by focusing on managing stateful, branching processes using a graph-based architecture for agent interaction. It supports advanced error handling, complex stateful interactions, and multi-agent workflows, making it suitable for applications requiring extensive data retrieval and knowledge fusion, especially in research settings. ([linkedin.com](https://www.linkedin.com/pulse/ai-agent-frameworks-june-2025-comprehensive-overview-chadi-abi-fadel-wcu5c?utm_source=openai))\n",
       "\n",
       "**CrewAI** is a Python-based framework tailored for orchestrating collaborative AI agents in complex, multi-step workflows across various domains. It features a role-based architecture, dynamic task planning, real-time performance monitoring, and orchestration of a variety of agents as distinct workers. CrewAI is ideal for complex projects requiring teamwork among agents, such as software development or project management. ([linkedin.com](https://www.linkedin.com/pulse/ai-agent-frameworks-june-2025-comprehensive-overview-chadi-abi-fadel-wcu5c?utm_source=openai))\n",
       "\n",
       "**AutoGen** developed by Microsoft, specializes in orchestrating multiple AI agents to form autonomous, event-driven systems capable of handling complex, multi-agent tasks seamlessly. It offers multi-agent orchestration, runtime convergence for scalable applications, and is ideal for enterprise-level applications needing event-driven workflows, such as customer service automation. ([linkedin.com](https://www.linkedin.com/pulse/ai-agent-frameworks-june-2025-comprehensive-overview-chadi-abi-fadel-wcu5c?utm_source=openai))\n",
       "\n",
       "**Amazon Bedrock AgentCore** introduced by AWS, is a platform designed to simplify the development and deployment of advanced AI agents. It includes modular services supporting the full production lifecycle, such as scalable serverless deployment, context management, secure service access, tool integration, and enhanced problem-solving capabilities with languages like JavaScript and Python. AgentCore emphasizes flexibility, allowing developers to use only the components they need, facilitating scalable and secure AI agent development. ([techradar.com](https://www.techradar.com/pro/aws-looks-to-super-charge-ai-agents-with-amazon-bedrock-agentcore?utm_source=openai))\n",
       "\n",
       "These frameworks represent the forefront of AI agent development, each contributing to the evolution of intelligent, autonomous systems across various industries. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(search_agent, message)\n",
    "\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As always, take a look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now use Structured Outputs, and include a description of the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See note above about cost of WebSearchTool\n",
    "\n",
    "HOW_MANY_SEARCHES = 3\n",
    "\n",
    "INSTRUCTIONS = f\"You are a helpful research assistant. Given a query, come up with a set of web searches \\\n",
    "to perform to best answer the query. Output {HOW_MANY_SEARCHES} terms to query for.\"\n",
    "\n",
    "# Use Pydantic to define the Schema of our response - this is known as \"Structured Outputs\"\n",
    "# With massive thanks to student Wes C. for discovering and fixing a nasty bug with this!\n",
    "\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this search is important to the query.\")\n",
    "\n",
    "    query: str = Field(description=\"The search term to use for the web search.\")\n",
    "\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem] = Field(description=\"A list of web searches to perform to best answer the query.\")\n",
    "\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searches=[WebSearchItem(reason='To find updated information on AI agent frameworks that are popular or emerging in 2025.', query='latest AI agent frameworks 2025'), WebSearchItem(reason='To explore specific frameworks and their functionalities, including tools and technologies in AI agent development.', query='AI agent development frameworks 2025'), WebSearchItem(reason='To gather insights on industry trends and popular choices in AI agent frameworks within the tech community for 2025.', query='trends in AI agent frameworks 2025')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(planner_agent, message)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email(body: str):\n",
    "    \"\"\" Send out an email with the given subject and HTML body \"\"\"\n",
    "    configuration = brevo_python.Configuration()\n",
    "    api_key = os.environ.get('BREVO_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"BREVO_API_KEY environment variable not set.\")\n",
    "    configuration.api_key['api-key'] = api_key\n",
    "    api_instance = transactional_emails_api.TransactionalEmailsApi(brevo_python.ApiClient(configuration))\n",
    "    sender = SendSmtpEmailSender(email=\"oliver@oliverdreger.cloud\", name=\"Oliver Dreger\")\n",
    "    to = [SendSmtpEmailTo(email=\"oliver.dreger@gmail.com\", name=\"Oliver Dreger\")]\n",
    "    send_smtp_email = SendSmtpEmail(    \n",
    "        sender=sender,\n",
    "        to=to,\n",
    "        subject=\"Sales email\",\n",
    "        text_content=body\n",
    "    )\n",
    "    try:\n",
    "        api_response = api_instance.send_transac_email(send_smtp_email)\n",
    "        print(\"Email sent successfully!\")\n",
    "        print(f\"Response: {api_response}\")\n",
    "    except brevo_python.ApiException as e:\n",
    "        print(f\"Exception when calling TransactionalEmailsApi->send_transac_email: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @function_tool\n",
    "# def send_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "#     \"\"\" Send out an email with the given subject and HTML body \"\"\"\n",
    "#     sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "#     from_email = Email(\"ed@edwarddonner.com\") # Change this to your verified email\n",
    "#     to_email = To(\"ed.donner@gmail.com\") # Change this to your email\n",
    "#     content = Content(\"text/html\", html_body)\n",
    "#     mail = Mail(from_email, to_email, subject, content).get()\n",
    "#     response = sg.client.mail.send.post(request_body=mail)\n",
    "#     return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='send_email', description='Send out an email with the given subject and HTML body', params_json_schema={'properties': {'body': {'title': 'Body', 'type': 'string'}}, 'required': ['body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x10cb6f600>, strict_json_schema=True, is_enabled=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"You are able to send a nicely formatted HTML email based on a detailed report.\n",
    "You will be provided with a detailed report. You should use your tool to send one email, providing the \n",
    "report converted into clean, well presented HTML with an appropriate subject line.\"\"\"\n",
    "\n",
    "email_agent = Agent(\n",
    "    name=\"Email agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[send_email],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\"\n",
    ")\n",
    "\n",
    "\n",
    "class ReportData(BaseModel):\n",
    "    short_summary: str = Field(description=\"A short 2-3 sentence summary of the findings.\")\n",
    "\n",
    "    markdown_report: str = Field(description=\"The final report\")\n",
    "\n",
    "    follow_up_questions: list[str] = Field(description=\"Suggested topics to research further\")\n",
    "\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next 3 functions will plan and execute the search, using planner_agent and search_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_searches(query: str):\n",
    "    \"\"\" Use the planner_agent to plan which searches to run for the query \"\"\"\n",
    "    print(\"Planning searches...\")\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    print(f\"Will perform {len(result.final_output.searches)} searches\")\n",
    "    return result.final_output\n",
    "\n",
    "async def perform_searches(search_plan: WebSearchPlan):\n",
    "    \"\"\" Call search() for each item in the search plan \"\"\"\n",
    "    print(\"Searching...\")\n",
    "    tasks = [asyncio.create_task(search(item)) for item in search_plan.searches]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(\"Finished searching\")\n",
    "    return results\n",
    "\n",
    "async def search(item: WebSearchItem):\n",
    "    \"\"\" Use the search agent to run a web search for each item in the search plan \"\"\"\n",
    "    input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "    result = await Runner.run(search_agent, input)\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next 2 functions write a report and email it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_report(query: str, search_results: list[str]):\n",
    "    \"\"\" Use the writer agent to write a report based on the search results\"\"\"\n",
    "    print(\"Thinking about report...\")\n",
    "    input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "    result = await Runner.run(writer_agent, input)\n",
    "    print(\"Finished writing report\")\n",
    "    return result.final_output\n",
    "\n",
    "async def send_email(report: ReportData):\n",
    "    \"\"\" Use the email agent to send an email with the report \"\"\"\n",
    "    print(\"Writing email...\")\n",
    "    result = await Runner.run(email_agent, report.markdown_report)\n",
    "    print(\"Email sent\")\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research...\n",
      "Planning searches...\n",
      "Will perform 3 searches\n",
      "Searching...\n",
      "Finished searching\n",
      "Thinking about report...\n",
      "Finished writing report\n",
      "Writing email...\n",
      "Email sent successfully!\n",
      "Response: {'message_id': '<202507272035.93916604807@smtp-relay.mailin.fr>',\n",
      " 'message_ids': None}\n",
      "Email sent\n",
      "Hooray!\n"
     ]
    }
   ],
   "source": [
    "query =\"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Research trace\"):\n",
    "    print(\"Starting research...\")\n",
    "    search_plan = await plan_searches(query)\n",
    "    search_results = await perform_searches(search_plan)\n",
    "    report = await write_report(query, search_results)\n",
    "    await send_email(report)  \n",
    "    print(\"Hooray!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As always, take a look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../../assets/thanks.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00cc00;\">Congratulations on your progress, and a request</h2>\n",
    "            <span style=\"color:#00cc00;\">You've reached an important moment with the course; you've created a valuable Agent using one of the latest Agent frameworks. You've upskilled, and unlocked new commercial possibilities. Take a moment to celebrate your success!<br/><br/>Something I should ask you -- my editor would smack me if I didn't mention this. If you're able to rate the course on Udemy, I'd be seriously grateful: it's the most important way that Udemy decides whether to show the course to others and it makes a massive difference.<br/><br/>And another reminder to <a href=\"https://www.linkedin.com/in/eddonner/\">connect with me on LinkedIn</a> if you wish! If you wanted to post about your progress on the course, please tag me and I'll weigh in to increase your exposure.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Notebook Summary by Gemini\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course. Here is a summary of the Jupyter Notebook `/Users/oliverdreger/Documents/mygit/GitHub/agents/2_openai/community_contributions/4_lab4_oliver.ipynb`.\n",
    "\n",
    "# Summary of Notebook \n",
    "\n",
    "<img src=\"../../assets/agentic_workflow.png\" width=\"25%\">\n",
    "<p style=\"text-align: left; font-size: 12px; color: #666; margin-top: 5px;\"><em>Source: Copilot</em></p>\n",
    "\n",
    "This Jupyter Notebook demonstrates how to build a sophisticated, multi-agent system to perform deep research on a given topic, synthesize the findings into a detailed report, and email the result. The notebook illustrates a classic agentic workflow by decomposing a complex task into a series of smaller, specialized tasks handled by different agents.\n",
    "\n",
    "The core of the notebook is the creation and orchestration of four distinct agents:\n",
    "\n",
    "1.  **`planner_agent`**: This agent is responsible for the initial planning phase. Given a research query, it uses a structured output (`WebSearchPlan` Pydantic model) to generate a list of several targeted web search queries. This ensures the research is comprehensive and well-structured from the start.\n",
    "\n",
    "2.  **`search_agent`**: This is a simple research assistant that takes a single search term and uses the `WebSearchTool` to find information. It then produces a concise, point-form summary of the results, designed to be easily consumed by the next agent in the chain.\n",
    "\n",
    "3.  **`writer_agent`**: This agent acts as a senior researcher. It receives the original query and the collection of summaries from the `search_agent`. Its task is to synthesize this information into a cohesive, detailed, and lengthy report (targeting over 1000 words). It also uses a structured output (`ReportData` Pydantic model) to return not only the markdown report but also a short summary and a list of suggested follow-up questions.\n",
    "\n",
    "4.  **`email_agent`**: The final agent in the workflow. It takes the generated report and uses a custom `send_email` tool (which integrates with the SendGrid API) to format the report into a clean HTML email and send it.\n",
    "\n",
    "The notebook then defines a series of `async` functions to orchestrate the workflow:\n",
    "*   `plan_searches()`: Calls the `planner_agent` to create the research plan.\n",
    "*   `perform_searches()`: Executes all the planned searches in parallel using `asyncio.gather` and the `search_agent`.\n",
    "*   `write_report()`: Feeds the search results to the `writer_agent` to generate the final report.\n",
    "*   `send_email()`: Uses the `email_agent` to send the completed report.\n",
    "\n",
    "The final \"Showtime!\" cell chains these functions together, demonstrating the complete, end-to-end automated process: from receiving a simple query to planning the research, executing it, writing a comprehensive report, and emailing it.\n",
    "\n",
    "Key concepts highlighted in this notebook include **agent decomposition**, the use of **structured outputs** with Pydantic for reliable inter-agent communication, and **asynchronous execution** for efficient parallel processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Transcript Summary by Gemini\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Building Deep Research Agents: Implementing OpenAI's Web Search Tool\n",
    "A summary of the course transcript for \"Day 4 - Building Deep Research Agents: Implementing OpenAI's Web Search Tool\" is as follows:\n",
    "\n",
    "The course on day four focuses on building a deep research agent, a common application of Agentic AI. This project involves creating an agent capable of searching the internet to research a given topic. This is similar to the deep research functionalities offered by frontier labs like OpenAI. The project will utilize previously learned concepts such as tools and structured outputs, and will also introduce hosted tools, which are run remotely by OpenAI. While the lab will be conducted in a notebook format for experimentation, the following day will transition to using Python modules.\n",
    "\n",
    "A significant new element introduced is the use of OpenAI's hosted tools. There are three such tools available: the web search tool, the file search tool for querying vector stores, and a computer tool for tasks like taking screenshots. This session will focus on the web search tool. The instructor notes that this tool is not inexpensive, costing around 2.5 cents per call with the cheapest model. A deep research task involving multiple searches could quickly accumulate costs. To manage this, users can monitor their spending and adjust settings. An alternative, more cost-effective method will be introduced in later weeks.\n",
    "\n",
    "The first agent created in this project is the \"search agent.\" Its system prompt, taken directly from OpenAI's documentation, instructs it to act as a research assistant that searches the web for a given term and provides a concise two to three-paragraph summary of the main points. This agent is configured to use the web search tool, and its use is made mandatory. The cost and performance of the agent can be managed by selecting the search context size (low, medium, or high) and the model (e.g., GPT-4 mini for a lower cost).\n",
    "\n",
    "The instructor then demonstrates running the search agent with the query \"latest AI agent frameworks in 2025.\" The results, presented in markdown, include a list of frameworks such as LangChain, LangGraph, Crew, and Autogen. The instructor comments on the mixed accuracy of the results, noting that some listed items aren't strictly agent frameworks. Finally, the process of examining the trace of the agent's execution in the OpenAI platform is shown, confirming that the web search tool was used as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Building a Planner Agent: Using Structured outputs with Pydantic in AI \n",
    "\n",
    "This is a summary of the course transcript for \"Day 4 - Building a Planner Agent: Using Structured outputs with Pydantic in AI\":\n",
    "\n",
    "The focus of this section of the course is on creating a \"planner agent.\" This agent's role is to take a user's query and generate a set of web searches to conduct thorough research on the topic. To manage costs associated with OpenAI's search tool, the number of searches is initially limited to three, though this can be adjusted.\n",
    "\n",
    "The system prompt for the planner agent is straightforward: \"You are a helpful research assistant. Given a query, come up with a set of web searches to perform to best answer that query output. And then the number three terms to query for.\"\n",
    "\n",
    "A key concept in building this agent is the use of structured outputs with the Pydantic library. This is achieved by defining a Python class, `WebSearchItem`, which inherits from Pydantic's `BaseModel`. This class acts as a schema for the desired output and includes two string fields: `reason` and `query`. The docstrings for these fields are important as they provide context to the model, helping it to populate them correctly.\n",
    "\n",
    "The instructor highlights a technique similar to \"chain of thought\" prompting: by asking the model to first generate a `reason` for a search before the `query` itself, the model is encouraged to \"think through\" its response, which often leads to higher-quality and more coherent search queries. It is emphasized that this is a result of the model's next-token prediction process, not genuine cognition.\n",
    "\n",
    "Another Pydantic class, `WebSearchPlan`, is defined to contain a single field, `searches`, which is a list of `WebSearchItem` objects.\n",
    "\n",
    "The planner agent is then created, using \"gpt-4-mini\" as the model. Crucially, the `output_type` for this agent is set to the `WebSearchPlan` class. This instructs the agent to return its output as a structured object conforming to this schema, rather than as plain text. The instructor clarifies that behind the scenes, this process involves converting the Pydantic model into a JSON schema that the language model is prompted to adhere to.\n",
    "\n",
    "Finally, a demonstration is shown where the planner agent is given the query \"latest AI agent frameworks in 2025.\" The agent successfully returns a `WebSearchPlan` object. This object contains a list of three `WebSearchItem` objects, each with a specific `reason` and a corresponding `query` to be used for searching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Building an End-to-End Research Pipeline with GPT-4 Agents & Async Tasks \n",
    "\n",
    "Here is a summary of the course transcript for \"Day 4 - Building an End-to-End Research Pipeline with GPT-4 Agents & Async Tasks\":\n",
    "\n",
    "This section of the course focuses on assembling the previously built components into a complete, end-to-end research pipeline. This pipeline will automate the entire process from receiving a query to planning searches, executing them, writing a report, and finally, emailing the result.\n",
    "\n",
    "The process begins by reintroducing a `send_email` tool, which is created by converting a Python function into an agent tool using the `@function_tool` decorator. This tool is then provided to a new `email_agent`. This agent is given the instructions and autonomy to take a detailed report, convert it into a well-presented HTML email, and create its own subject line before sending it.\n",
    "\n",
    "Next, a \"researcher\" or \"writer\" agent is created. This senior agent's task is to take the original query and the initial research gathered by other agents and synthesize it into a cohesive, lengthy, and detailed report in Markdown. A key feature of this agent is its use of structured outputs. It is configured to return a Pydantic `ReportData` object, which has three fields: a `short_summary`, the `full_markdown_final_report`, and `follow_up_suggestions`.\n",
    "\n",
    "The core of the lesson is the \"crunch time\" section, where five asynchronous functions are defined to orchestrate the entire workflow:\n",
    "\n",
    "1.  **`plan_searches`**: This function calls the `planner_agent` to generate a list of web searches based on the initial query.\n",
    "2.  **`perform_searches`**: This function takes the search plan and executes all the individual searches *in parallel*. This is a crucial efficiency step achieved using Python's `asyncio.gather`, which runs multiple instances of the `search_agent` concurrently.\n",
    "3.  **`search_for_item`**: This is the helper function called by `perform_searches` for each individual search, invoking the `search_agent`.\n",
    "4.  **`write_report`**: This function calls the `writer_agent`, providing it with the query and the collected search results to generate the final structured `ReportData` object.\n",
    "5.  **`send_email`**: This final function calls the `email_agent` to format and send the generated report.\n",
    "\n",
    "The lesson culminates in the execution block where these asynchronous functions are `await`ed in sequence, demonstrating the complete pipeline in action. The flow starts with a query, plans the necessary searches, performs them simultaneously, synthesizes the results into a detailed report, and concludes by sending the final report as an HTML email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4 - Building a Deep Research Agent: Parallel Searches with AsyncIO\n",
    "\n",
    "Here is a summary of the transcript \"Day 4 - Building a Deep Research Agent: Parallel Searches with AsyncIO\":\n",
    "\n",
    "The session begins by confirming the successful completion of the deep research pipeline that was built. The initial run, configured to perform three searches, finished successfully and sent a well-formatted HTML email. This email contained a good introduction, a detailed analysis of AI agent frameworks (mentioning \"Crew\" at the top), and functional reference links at the bottom. The instructor expresses satisfaction with building a powerful deep research framework with surprisingly minimal code, highlighting its potential for expansion.\n",
    "\n",
    "To demonstrate this potential, the instructor scales up the operation by increasing the number of searches from three to twenty. This change is made in the `planner_agent`'s instructions. After re-running the entire pipeline, the new, more extensive research is completed. The resulting email report, while identifying similar key frameworks, is significantly more substantive. It includes more detailed information, such as the applications and benefits associated with each framework, a section on commercial implications, and a concluding summary.\n",
    "\n",
    "A key takeaway highlighted is the efficiency gained through parallel processing. By examining the execution trace, the instructor shows that after the initial `planner_agent` ran, all twenty `search_agent` tasks were executed simultaneously thanks to Python's `asyncio`. This parallel execution was followed by the sequential execution of the `writer_agent` and the `email_agent` to synthesize the report and send the final email.\n",
    "\n",
    "The lesson concludes with the instructor encouraging students to think about how they could further enhance and build upon this deep research agent. It is also mentioned that the next session will focus on packaging this entire framework into a standalone, take-away application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
